# -*- coding: utf-8 -*-
"""VOSTPT_FMA_ANALYSIS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nDTNPdHLoKZm18ySQAvWKAQY9fGkjj0_

# ANALYSIS OF ADVERSE WEATHER PHENOMENA (AN√ÅLISE DE FEN√ìMENOS METEOROL√ìGICOS ADVERSOS)

## DATA VIA FOGOS.PT API

### Objectives

**This notebook allows for the analysis of data coming from the FOGOS.PT API and create reports and visualizations for a determined time period, normally associated with an adverse weather phenomena. The origin of the data provided by the API comes directly from [ANEPC](https://prociv.pt)**


---

### Objectivos

**Este *notebook* permite analisar os dados provenientes da API do FOGOS.PT e criar relat√≥rios e visualiza√ß√µes de um determinado per√≠odo temporal, normalmente associado a um fen√≥meno meteorol√≥gico adverso. A origem dos dados fornecidos pela API vem diretamente da [ANEPC](https://prociv.pt)**



---



### Credits

**Developed by [Jorge Gomes](https://twitter.com/jgomes_eu) for VOST Portugal with ü§ç**

**API developed by [Jo√£o Pina](https://twitter.com/tomahock)**

### License (Licen√ßa)


<a href="https://colab.research.google.com/drive/1nDTNPdHLoKZm18ySQAvWKAQY9fGkjj0_?usp=sharing">VOST FMA Analysis</a> by <a href="https://twitter.com/jgomes_eu">Jorge Gomes</a> for <a href="https://vost.pt">VOST Portugal</a> is licensed under<br>
<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank">Attribution-NonCommercial-ShareAlike 4.0 International<br>

# Libraries (Bibliotecas)

**Install the libraries that are not installed by default in Google Colab**

**Instala as bibliotecas que n√£o s√£o instaladas por defeito no Google Colab**

---

**Import all libraries to the environment**
**Importa todas as bibliotecas para o ambiente de desenvolvimento**
"""

!pip install h3pandas
!pip install unidecode

"""#### Import required libraries"""

import pandas as pd
import geopandas as gpd
import json
import h3pandas
import unidecode
import matplotlib.pyplot as plt
import requests
import datetime as dt
from datetime import datetime, timedelta, date
import seaborn as sns
import folium
from folium.plugins import HeatMap
import matplotlib
import matplotlib.dates as mdates
from matplotlib.font_manager import FontProperties
from google.colab import files
import zipfile
import tempfile
import shutil
import os
import numpy as np

"""#Data Files for Analysis (Dados para An√°lise )
**API FOGOS.PT**

https://api.fogos.pt/v2/incidents/search?all=1&after= **2023-10-16** &limit=30000

**Please change the date to the day before the day you want to analyse**

**Por favor, altera a data para o dia anterior ao dia que deseja analisar**
"""

# Define the call to the API
url_bar="https://api.fogos.pt/v2/incidents/search?all=1&after=2023-10-15&limit=30000"
# Get response from the API
response = requests.get(url_bar)
# Get the json content from the response
json = response.json()
# Create a pandas dataframe
raw_data = pd.json_normalize(json,'data')
# This is necessary to set the date of the dataset to local time
raw_data['date_time']=pd.to_datetime(raw_data['date'] + ' '+raw_data['hour'],format='%d-%m-%Y %H:%M')

# Define the naturezaCode for FMA (Official from ANEPC)
# Convert the codes to strings since the unique values in 'naturezaCode' are strings
codes = ['1101', '1103', '1107', '1109', '1111', '1115', '1125',
         '3301', '3303', '3305', '3307', '3309', '3311', '3313',
         '3315', '3321', '3323', '3325', '3329', '3333',
         '2501', '2503', '2507', '2509']

# Filter the data
data = raw_data[raw_data['naturezaCode'].isin(codes)].copy()
data['date_time']=pd.to_datetime(data['date'] + ' '+data['hour'],format='%d-%m-%Y %H:%M')

"""## Optional Filtering
**Use this just in case you want to have a report for the last x hours**
"""

# Get the current time
current_time = datetime.now()

# Calculate the time for x hours ago
hours_ago = current_time - timedelta(hours=6)

# Filter the dataframe
data = data[data['date_time'] > hours_ago]

"""#### Only use this if you want to specify the interval a specific interval"""

specific_start_datetime = '2023-10-16 00:00:00'  # fill in your specific start datetime
specific_end_datetime = '2023-10-22 23:59:00'    # fill in your specific end datetime
mask = (data['date_time'] >= specific_start_datetime) & (data['date_time'] <= specific_end_datetime)
data = data.loc[mask]

"""## DATA TREATMENT / TRATAMENTO DE DADOS"""

# Define the Period that is being analysed
start_date = data['date_time'].min()
end_date = data['date_time'].max()

# Convert the timestamps to strings in the desired format
start_date_str = start_date.strftime('%Y-%m-%d %H:%M')
end_date_str = end_date.strftime('%Y-%m-%d %H:%M')

print(start_date_str, " a ", end_date_str)

"""# Dataset Summary (Resumo dos Dados)

**This code analyzes incident data, calculating the total number of occurrences, the top three incident types, and the top three counties where the biggest number of occurrences happened. It also examines incident frequency by hour and computes the average number of operational personnel involved. The code identifies the incident with the highest personnel involvement and extracts relevant details. Results are collected in a dictionary, translated to Portuguese, and formatted. The code calculates a time interval for peak incident frequency and generates a detailed Portuguese summary, offering insights into occurrence frequency, nature, timing, and response.**

**The second block of code generates a series of tweets with the same insights to be published**

---

**Este c√≥digo analisa dados de ocorr√™ncias, calculando o n√∫mero total de ocorr√™ncias, os tr√™s principais tipos de incidentes e os tr√™s principais concelhos onde existiram o maior n√∫mero de ocorr√™ncias. Tamb√©m examina a frequ√™ncia de ocorr√™ncias por hora e calcula o n√∫mero m√©dio de pessoal operacional envolvido. O c√≥digo identifica o incidente com maior envolvimento do pessoal e extrai detalhes relevantes. Os resultados s√£o coletados em um dicion√°rio, traduzidos para portugu√™s e formatados. O c√≥digo calcula um intervalo de tempo para a frequ√™ncia de pico de incidentes e gera um resumo detalhado em portugu√™s, oferecendo insights sobre a frequ√™ncia, natureza, tempo e resposta da ocorr√™ncia**

**O segundo bloco de c√≥digo gera uma s√©rie de tweets com os mesmos insights para serem publicados**

##### Sumary (Resumo)
"""

# Duplicate Dataframe for data integrity purposes
incident_data_full = data

# Count of Incidents
total_incidents = len(incident_data_full)

# Incidents by Type (Natureza)
incidents_by_natureza = incident_data_full['natureza'].value_counts().head(3)

# Incidents by Location (Concelho)
incidents_by_concelho = incident_data_full['concelho'].value_counts().head(3)

# Convert to DataFrame
incidents_by_concelho_df = incidents_by_concelho.reset_index()
incidents_by_concelho_df.columns = ['concelho', 'number_of_incidents']

# Incident Frequency Over Time (per hour)
# Extract the hour from the datetime
incident_data_full['hour'] = incident_data_full['date_time'].dt.hour

# Count the number of incidents for each hour
incidents_by_hour = incident_data_full['hour'].value_counts().sort_index()

# Response Statistics
# Calculating the average number of personnel (man) involved in incidents
average_personnel = incident_data_full['man'].mean()

# Find the incident with the most personnel involved
max_personnel_incident = incident_data_full.loc[incident_data_full['man'].idxmax()]

# Extract relevant information from the incident
max_personnel_natureza = max_personnel_incident['natureza']
max_personnel_concelho = max_personnel_incident['concelho']
max_personnel_district = max_personnel_incident['district']
max_personnel_count = max_personnel_incident['man']

# Create a column combining date and hour
incident_data_full['date_hour'] = incident_data_full['date_time'].dt.strftime('%Y-%m-%d %H')
incidents_by_date_hour = incident_data_full['date_hour'].value_counts().sort_index()
max_date_hour = incidents_by_date_hour.idxmax()
max_incidents = incidents_by_date_hour.max()
max_date = datetime.strptime(max_date_hour, '%Y-%m-%d %H').date()
max_hour = datetime.strptime(max_date_hour, '%Y-%m-%d %H').hour
time_interval_start = f"{max_hour:02}:00"
time_interval_end = f"{(max_hour + 1) % 24:02}:00"

# Mapping of days of the week from English to Portuguese
days_of_week_pt = {
    'Monday': 'Segunda-feira',
    'Tuesday': 'Ter√ßa-feira',
    'Wednesday': 'Quarta-feira',
    'Thursday': 'Quinta-feira',
    'Friday': 'Sexta-feira',
    'Saturday': 'S√°bado',
    'Sunday': 'Domingo',
}

months_pt = {
    1: 'Janeiro',
    2: 'Fevereiro',
    3: 'Mar√ßo',
    4: 'Abril',
    5: 'Maio',
    6: 'Junho',
    7: 'Julho',
    8: 'Agosto',
    9: 'Setembro',
    10: 'Outubro',
    11: 'Novembro',
    12: 'Dezembro',
}

# Convert the 'max_date' string back to a datetime object to use 'strftime'
max_date_obj = datetime.strptime(str(max_date), '%Y-%m-%d')


# Get the day of the week in English
day_of_week_en = max_date_obj.strftime('%A')

# Translate to Portuguese using the mapping
day_of_week_pt = days_of_week_pt.get(day_of_week_en, day_of_week_en)

day = max_date.day
month = months_pt[max_date.month]  # Translate the month to Portuguese
year = max_date.year

# Format the date
date_pt = f"{day} de {month} de {year}"


# Collecting the results
statistics = {
    "total_incidents": total_incidents,
    "incidents_by_natureza": incidents_by_natureza,
    "incidents_by_concelho": incidents_by_concelho,
    "incidents_by_hour": incidents_by_hour,
    "average_personnel_per_incident": average_personnel,
    "start_date": start_date_str,
    "end_date": end_date_str
}

# dictionary key and variable references
translation_dict = {
    "total_incidents": "Total de Ocorr√™ncias",
    "incidents_by_natureza": "Tipos de Ocorr√™ncias",
    "incidents_by_concelho": "Ocorr√™ncias por Concelho",
    "incidents_by_hour": "Dia com mais Ocorr√™ncias",
    "average_personnel_per_incident": "M√©dia de Operacionais por Ocorr√™ncia",
    "max_personnel_incident": "Ocorr√™ncia com Mais Operacionais Envolvidos",
    "start_date": "Data de In√≠cio",
    "end_date": "Data de Fim"
}

# Convert statistics dictionary keys and certain values to Portuguese
statistics_pt = {
    translation_dict[key]: value if key not in ['incidents_by_natureza', 'incidents_by_concelho'] else {
        sub_key: sub_value for sub_key, sub_value in value.items()
    } for key, value in statistics.items()
}

# Calculate the time interval for the "Frequ√™ncia de Ocorr√™ncias ao Longo do Tempo (por hora)" section
max_hour = statistics['incidents_by_hour'].idxmax()
time_interval_start = f"{max_hour:02}:00"
time_interval_end = f"{(max_hour + 1) % 24:02}:00"

# Generate a summary text in Portuguese, and make sure to use the correct keys
summary_text = f"""
**Per√≠odo analisado: De {statistics['start_date']} a {statistics['end_date']}**

1. {translation_dict['total_incidents']}: {statistics['total_incidents']} ocorr√™ncias
2. {translation_dict['incidents_by_natureza']}: Os tipos de ocorr√™ncias mais comuns foram: {', '.join([f'{natureza} ({count} ocorr√™ncias)' for natureza, count in statistics['incidents_by_natureza'].items()])}.
3. {translation_dict['incidents_by_concelho']}: Os concelhos com mais ocorr√™ncias foram: {', '.join([f'{concelho} ({count} ocorr√™ncias)' for concelho, count in statistics['incidents_by_concelho'].items()])}.
4. {translation_dict['incidents_by_hour']}: O dia com mais ocorr√™ncias foi {max_date} ({day_of_week_pt}), entre as {time_interval_start}h e as {time_interval_end}h ({max_incidents} ocorr√™ncias).
5. {translation_dict['average_personnel_per_incident']}: Em m√©dia, cerca de {statistics['average_personnel_per_incident']:.0f} operacionais estiveram envolvidos por ocorr√™ncia.
6. {translation_dict['max_personnel_incident']}: A ocorr√™ncia com mais operacionais envolveu {max_personnel_count} operacionais. Ocorr√™ncia de natureza {max_personnel_natureza} no concelho de {max_personnel_concelho}, distrito de {max_personnel_district}.

* **As ocorrencias do RSB de Lisboa n√£o s√£o comunicadas ao SADO / ANEPC pelo que nao est√£o aqui contabilizadas**

"""

# Print summary text
print(summary_text)

"""##### Tweet Summary (Resumo para o Twitter)"""

# Create a series of tweets in VOST Portugal's style
tweets = []

# Tweet 1: Introduction
tweet = "üö®üìä Resumo de Ocorr√™ncias üìäüö®\n\n"
tweet += f"üìÖ Per√≠odo analisado: {start_date_str} a {end_date_str}\n"
tweet += f"‚ÑπÔ∏è Total de Ocorr√™ncias: {statistics['total_incidents']} ocorr√™ncias\n"
tweet += "üëá Mais detalhes abaixo üëá"
tweets.append(tweet)

# Tweet 2: Types of Incidents
tweet = "üîç Tipos de Ocorr√™ncias Mais Comuns:\n"
for natureza, count in statistics['incidents_by_natureza'].items():
    tweet += f"‚Ä¢ {natureza}: {count} ocorr√™ncias\n"
tweets.append(tweet)

# Tweet 3: Incidents by Location
tweet = "üìç Ocorr√™ncias por Concelho:\n"
for concelho, count in statistics['incidents_by_concelho'].items():
    tweet += f"‚Ä¢ {concelho}: {count} ocorr√™ncias\n"
tweets.append(tweet)



# Use the formatted date in your tweet
tweet = f"üìÜ O dia com mais ocorr√™ncias foi {day_of_week_pt}, {date_pt}\n"
tweet += f"üïí durante as {time_interval_start} e as {time_interval_end}\n"
tweet += f"tendo-se registado {max_incidents} ocorr√™ncias\n"
tweets.append(tweet)

# Tweet 4: Day with most occurences
tweet = f"üìÜ O dia com mais ocorr√™ncias foi {day_of_week_pt}, {date_pt} durante as {time_interval_start} e as {time_interval_end} tendo-se registado {max_incidents} ocorr√™ncias"
tweets.append(tweet)

# Tweet 5: Average Personnel per Incident
tweet = f"üë• M√©dia de Operacionais por Ocorr√™ncia: {statistics['average_personnel_per_incident']:.0f}\n"
tweets.append(tweet)

# Tweet 6: Incident with Most Personnel
tweet = f"üöí Maior Mobiliza√ß√£o de Recursos:\n"
tweet += f"‚Ä¢ Ocorr√™ncia de {max_personnel_natureza}\n"
tweet += f"‚Ä¢ Concelho: {max_personnel_concelho}, Distrito: {max_personnel_district}\n"
tweet += f"‚Ä¢ {max_personnel_count} operacionais envolvidos\n"
tweets.append(tweet)

# Tweet 7 Disclaimer
tweet = f"**As ocorrencias do RSB da @CamaraLisboa n√£o s√£o comunicadas ao SADO / @ProteccaoCivil pelo que nao est√£o aqui contabilizadas"
# Print the individual tweets
for i, tweet in enumerate(tweets):
    print(f"Tweet {i + 1}:")
    print(tweet)
    print("\n")

"""## Data Visualisation Products (Produtos de Visualiza√ß√£o de Dados)

**The following code blocks produces, and saves in the local computer, a set of visualizations that can help you tell the story of the event**

---

**Os blocos de c√≥digo a seguir produzem e salvam no computador local um conjunto de visualiza√ß√µes que podem ajudar voc√™ a contar a hist√≥ria do evento**

#### Occurences by District (Ocorr√™ncias por Distrito)

This code analyzes occurrence data to identify the top 10 types of occurrences (natureza) in different districts. It calculates the frequency of each natureza per district and uses this data to create a heatmap visualization. The heatmap displays these frequencies using color gradations, providing a clear visual representation of the most common occurrence types across districts within a specified date range. Labels, titles, and annotations are added for context, and the final high-resolution image is saved for sharing or further use.


---


Este c√≥digo analisa dados de ocorr√™ncias para identificar os 10 principais tipos de ocorr√™ncias (natureza) em diferentes distritos. Calcula a frequ√™ncia de cada natureza por distrito e usa esses dados para criar uma visualiza√ß√£o em mapa de calor. O mapa de calor exibe essas frequ√™ncias usando gradua√ß√µes de cor, fornecendo uma representa√ß√£o visual clara dos tipos de ocorr√™ncias mais comuns entre os distritos dentro de um intervalo de datas especificado. R√≥tulos, t√≠tulos e anota√ß√µes s√£o adicionados para contexto, e a imagem final em alta resolu√ß√£o √© gravada para partilha ou uso posterior.
"""

# Calculate the frequency of each 'natureza' for each district
natureza_district_crosstab = pd.crosstab(incident_data_full['natureza'], incident_data_full['district'])

# Get the top 10 'natureza' types
top_naturezas = incident_data_full['natureza'].value_counts().nlargest(10).index

# Filter the crosstab for only the top 10 'natureza' types
top_natureza_district_crosstab = natureza_district_crosstab.loc[top_naturezas]


# Create the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(top_natureza_district_crosstab, annot=True, fmt="d", cmap='Blues', linewidths=.5,cbar=False)

# Set the labels
plt.xlabel('Distritos')
plt.ylabel('Tipo de Ocorr√™ncia (Top 10)')
plt.title(f'Ocorr√™ncias por Distrito\n{start_date_str} to {end_date_str}', loc='center')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
# Save the plot for dissemination
filename=f'distrito_high_res_{end_date_str}.png'
plt.savefig(filename, dpi=300, bbox_inches='tight')
files.download(filename)
plt.show()

"""#### Occurrences by Municipality for the District with the most Occurrences (Ocorr√™ncias por Concelho para o Distrito com mais Ocorr√™ncias)

This code analyzes occurrence data to determine the district with the highest number of occurrences. It first identifies the district with the most occurrences (top_district) and then filters the dataset for that specific district. Within this district, the code calculates the frequency of each occurrence type (natureza) for each county (concelho). After identifying the top 10 occurrence types in the district, it creates a heatmap to visually display the frequency of these top occurrences across the counties. The heatmap uses color intensity to represent frequency differences, and numerical annotations provide specific counts. Custom labels and titles are used, highlighting the district in focus and the analysis period. The final visualization is saved as a high-resolution image for download or future reference.


---


Este c√≥digo analisa dados de ocorr√™ncias para determinar o distrito com o maior n√∫mero de ocorr√™ncias. Primeiro, identifica o distrito com mais ocorr√™ncias (top_district) e, em seguida, filtra o conjunto de dados para esse distrito espec√≠fico. Dentro deste distrito, o c√≥digo calcula a frequ√™ncia de cada tipo de ocorr√™ncia (natureza) para cada concelho (concelho). Ap√≥s identificar os 10 principais tipos de ocorr√™ncias no distrito, ele cria um mapa de calor para exibir visualmente a frequ√™ncia dessas principais ocorr√™ncias nos concelhos. O mapa de calor usa a intensidade da cor para representar diferen√ßas de frequ√™ncia, e anota√ß√µes num√©ricas fornecem contagens espec√≠ficas. R√≥tulos e t√≠tulos personalizados s√£o usados, destacando o distrito em foco e o per√≠odo de an√°lise. A visualiza√ß√£o final √© salva como uma imagem de alta resolu√ß√£o para download ou refer√™ncia futura.
"""

# Identify the district with the most incidents
top_district = incident_data_full['district'].value_counts().idxmax()

# Filter the data for that district
district_data = incident_data_full[incident_data_full['district'] == top_district]

# Calculate the frequency of each 'natureza' for each 'concelho' in the top district
natureza_concelho_crosstab = pd.crosstab(district_data['natureza'], district_data['concelho'])

# Get the top 10 'natureza' types
top_naturezas = district_data['natureza'].value_counts().nlargest(10).index

# Filter the crosstab for only the top 10 'natureza' types
top_natureza_concelho_crosstab = natureza_concelho_crosstab.loc[top_naturezas]

# Create the heatmap
plt.figure(figsize=(12, 8))
heatmap = sns.heatmap(top_natureza_concelho_crosstab, annot=True, fmt="d", cmap='Blues', linewidths=.5, cbar=False)

# Set the labels and titles with the top district
plt.xlabel('Concelhos')
plt.ylabel('Tipo de Ocorr√™ncia (Top 10)')
plt.title(f'Ocorr√™ncias por Concelho no distrito de {top_district}\n Per√≠odo analisado: {start_date_str} a {end_date_str}', loc='center')
plt.xticks(rotation=90)
plt.yticks(rotation=0)

# Save the figure in high resolution
filename=f'concelho_high_res_{end_date_str}.png'
plt.savefig(filename, dpi=300, bbox_inches='tight')
files.download(filename)
plt.show()

"""#### Counties Top 10 in Occurences (Concelhos Top 10 in Occurences)

**This code identifies the top 10 affected counties ("concelho") in the dataset of incidents. It counts the occurrences for each county, creates a DataFrame to store these top 10 counties along with their incident counts, and then generates a DataFrame for these top counties exclusively.**

**Subsequently, it creates a heatmap using Seaborn, visually displaying the frequencies of various incident types ("natureza") across the top 10 counties. Labels and titles are added for clarity, and the resulting heatmap is saved as a high-resolution image, named after the end date of the analyzed period, for sharing or further use.**

---

**Este c√≥digo identifica os 10 concelhos mais afetados (‚Äúconcelho‚Äù) no conjunto de dados de incidentes. Ele conta as ocorr√™ncias para cada concelho, cria um DataFrame para armazenar esses 10 principais concelhos junto com suas contagens de ocorr√™ncias correspondentes e, em seguida, gera um DataFrame exclusivamente para esses principais concelhos.**

**Depois √© criado um mapa de calor usando Seaborn, exibindo visualmente as frequ√™ncias de v√°rios tipos de ocorr√™ncias ("natureza") nos 10 principais concelhos. R√≥tulos e t√≠tulos s√£o adicionados para maior clareza, e o mapa de calor resultante √© salvo como uma imagem de alta resolu√ß√£o, com o nome da data final do per√≠odo analisado, para partilha ou uso posterior.**
"""

# Calculate the top 10 most affected concelhos in the entire dataset
top_10_concelhos = incident_data_full['concelho'].value_counts().nlargest(10)

# Create a DataFrame to hold the top 10 concelhos and their counts
top_10_concelhos_df = top_10_concelhos.reset_index()
top_10_concelhos_df.columns = ['concelho', 'number_of_incidents']

# Create a DataFrame for the top 10 concelhos
top_10_concelhos_list = top_10_concelhos.index.tolist()
incident_data_top_10_concelhos = incident_data_full[incident_data_full['concelho'].isin(top_10_concelhos_list)]

# Create a crosstab to count the occurrences of natureza in the top 10 concelhos
natureza_concelho_crosstab = pd.crosstab(incident_data_top_10_concelhos['natureza'], incident_data_top_10_concelhos['concelho'])

# Create the heatmap
plt.figure(figsize=(12, 8))
heatmap = sns.heatmap(natureza_concelho_crosstab, annot=True, fmt="d", cmap='Blues', linewidths=.5, cbar=False)

# Set the labels and titles
plt.xlabel('Concelhos (Top 10)')
plt.ylabel('Tipo de Ocorr√™ncia')
plt.title(f'Ocorr√™ncias por Concelho e Tipo de Ocorr√™ncia (Top 10 de todos os Concelhos)\n Per√≠odo analisado: {start_date_str} a {end_date_str}', loc='center')
plt.xticks(rotation=90)
plt.yticks(rotation=0)

# Save the figure in high resolution
filename = f'heatmap_concelho_top10_natureza_{end_date_str}.png'
plt.savefig(filename, dpi=300, bbox_inches='tight')
files.download(filename)
plt.show()

"""#### Occurrences by Parish for the most affected Municipality (Ocorr√™ncias por Freguesia para o Concelho mais afetado)

This code analyzes occurrence data to identify the county (concelho) with the highest number of occurrences. It first finds the concelho with the most occurrences and then filters the data for that specific concelho. Within this concelho, the code calculates the frequency of each occurrence type (natureza) for each parish (freguesia). After determining the top 10 occurrence types in the concelho, it creates a heatmap to visually display the frequency of these top occurrences across the parishes. The heatmap uses color intensity to indicate frequency differences, and numerical annotations provide specific counts. Custom labels and titles are used, emphasizing the most affected concelho and the analysis period. The final visualization is saved as a high-resolution image for download or future reference.


---


Este c√≥digo analisa dados de ocorr√™ncias para identificar o concelho (concelho) com o maior n√∫mero de ocorr√™ncias. Primeiro, descobre o concelho com mais ocorr√™ncias e depois filtra os dados para esse concelho espec√≠fico. Dentro deste concelho, o c√≥digo calcula a frequ√™ncia de cada tipo de ocorr√™ncia (natureza) para cada freguesia (freguesia). Ap√≥s determinar os 10 principais tipos de ocorr√™ncias no concelho, ele cria um mapa de calor para exibir visualmente a frequ√™ncia dessas principais ocorr√™ncias nas freguesias. O mapa de calor usa a intensidade da cor para indicar diferen√ßas de frequ√™ncia, e anota√ß√µes num√©ricas fornecem contagens espec√≠ficas. R√≥tulos e t√≠tulos personalizados s√£o usados, enfatizando o concelho mais afetado e o per√≠odo de an√°lise. A visualiza√ß√£o final √© salva como uma imagem de alta resolu√ß√£o para download ou refer√™ncia futura.

"""

# Identify the concelho with the most incidents across the entire dataset
top_concelho = incident_data_full['concelho'].value_counts().idxmax()

# Filter the data for that concelho
concelho_data = incident_data_full[incident_data_full['concelho'] == top_concelho]

# Calculate the frequency of each 'natureza' for each 'freguesia' in the top concelho
natureza_freguesia_crosstab = pd.crosstab(concelho_data['natureza'], concelho_data['freguesia'])

# Get the top 10 'natureza' types
top_naturezas_concelho = concelho_data['natureza'].value_counts().nlargest(10).index

# Filter the crosstab for only the top 10 'natureza' types
top_natureza_freguesia_crosstab = natureza_freguesia_crosstab.loc[top_naturezas_concelho]

# Create the heatmap
plt.figure(figsize=(12, 8))
heatmap = sns.heatmap(top_natureza_freguesia_crosstab, annot=True, fmt="d", cmap='Blues', linewidths=.5, cbar=False)

# Set the labels and titles with the top concelho
plt.xlabel('Freguesias')
plt.ylabel('Tipo de Ocorr√™ncia (Top 10)')
plt.title(f'Ocorr√™ncias por freguesia no concelho mais afetado {top_concelho}\nPer√≠odo Analisado: {start_date_str} a {end_date_str}', loc='center')
plt.xticks(rotation=45,fontsize=8)
plt.yticks(rotation=0)

# Save the figure in high resolution
filename=f'freguesia_high_res_{end_date_str}.png'
plt.savefig(filename, dpi=300, bbox_inches='tight')
files.download(filename)
plt.show()

"""#### Interactive Heatmap for Occurences (Mapa Ocorr√™ncias Interactivo)

This code generates an interactive map to visualize different types of occurrences (natureza) in Portugal based on their geographical coordinates. It begins by creating a base map centered around Portugal, utilizing a dark theme from 'CartoDB dark_matter'. The map identifies unique natureza types from the dataset and prepares to create individual layers for each.

A blue gradient color scale is defined for visual consistency across the heatmap layers. For each unique natureza, the code filters the relevant data and extracts the latitude and longitude information to construct heatmaps. These heatmaps, indicating the concentration of occurrences, are added as separate layers to the base map, each corresponding to a different natureza.

Layer controls are implemented, allowing viewers to toggle between the different heatmap layers for a comparative analysis. The interactive map, complete with all the layers and controls, is saved as an HTML file for accessibility and sharing, and is also programmed to be displayed within the execution environment.


---


Este c√≥digo gera um mapa interativo para visualizar diferentes tipos de ocorr√™ncias (natureza) em Portugal com base em suas coordenadas geogr√°ficas. Come√ßa criando um mapa base centrado em Portugal, utilizando um tema escuro de 'CartoDB dark_matter'. O mapa identifica tipos √∫nicos de natureza a partir do conjunto de dados e cria camadas individuais para cada um.

Uma escala de cores com gradiente azul √© definida para consist√™ncia visual nas camadas do mapa de calor. Para cada natureza √∫nica, o c√≥digo filtra os dados relevantes e extrai as informa√ß√µes de latitude e longitude para construir mapas de calor. Esses mapas de calor, indicando a concentra√ß√£o de ocorr√™ncias, s√£o adicionados como camadas separadas ao mapa base, cada um correspondendo a uma diferente natureza.

Controles de camada s√£o implementados, permitindo que os utilizadores alternem entre as diferentes camadas de mapa de calor para uma an√°lise comparativa. O mapa interativo, completo com todas as camadas e controles, √© salvo como um arquivo HTML para acessibilidade e compartilhamento, e tamb√©m est√° programado para ser exibido dentro do ambiente de execu√ß√£o.
"""

# Create a base map with a dark theme
map = folium.Map(location=[39.3999, -8.2245], zoom_start=6, tiles='CartoDB dark_matter')  # coordinates for Portugal

# List of 'natureza' to create layers for
naturezas = incident_data_full['natureza'].unique()

# Layer control
layer_control = folium.LayerControl(collapsed=False)

# Define a blue gradient color scale
gradient = {0.2: 'blue', 0.4: 'deepskyblue', 0.6: 'cyan', 0.8: 'aqua', 1.0: 'white'}

# Create a heatmap layer for each 'natureza'
for natureza in naturezas:
    filtered_data = incident_data_full[incident_data_full['natureza'] == natureza]
    heat_data = [[row['lat'], row['lng']] for index, row in filtered_data.iterrows()]
    heat_layer = HeatMap(heat_data, name=natureza, show=False, gradient=gradient,radius=10)
    heat_layer.add_to(map)

# Add layer control to the map
layer_control.add_to(map)

# Save it to a file
filename=f'heatmap_map_natureza_layers_dark_{end_date_str}.html'
map.save(filename)
files.download(filename)
# Display the map
map

"""### Honeycomb Hexagonal Map (Mapa Hexagonal)

This code analyzes occurrence data across different districts in Portugal by visualizing the data on a hexagonal grid map. It begins by downloading a shapefile containing district boundaries from a specified URL and extracts this data for use. The code then loads and processes the geographical data, excluding specific regions and ensuring the correct Coordinate Reference System (CRS) is used.

Hexagons are generated to represent districts, and occurrence data is aggregated by district and merged with the hexagon geodataframe. The visualization is created on a dark-themed map, with hexagons colored according to the total count of occurrences, using a blue color scheme. The map is customized for readability and aesthetics, including a specific title and a dark background. The final map is saved as a high-resolution image for sharing or further use.


---


Este c√≥digo analisa dados de ocorr√™ncias em diferentes distritos de Portugal, visualizando os dados em um mapa de grade hexagonal. Ele come√ßa baixando um shapefile contendo limites de distritos de uma URL espec√≠fica e extrai esses dados para uso. O c√≥digo ent√£o carrega e processa os dados geogr√°ficos, excluindo regi√µes espec√≠ficas e garantindo que o Sistema de Refer√™ncia de Coordenadas (CRS) correto seja usado.

Hex√°gonos s√£o gerados para representar distritos, e os dados de ocorr√™ncia s√£o agregados por distrito e mesclados com o geodataframe hexagonal. A visualiza√ß√£o √© criada em um mapa com tema escuro, com hex√°gonos coloridos de acordo com a contagem total de ocorr√™ncias, usando um esquema de cores azul. O mapa √© personalizado para legibilidade e est√©tica, incluindo um t√≠tulo espec√≠fico e um fundo escuro. O mapa final √© salvo como uma imagem de alta resolu√ß√£o para compartilhamento ou uso posterior.
"""

# Fetch the shapefile from dados.gov.pt

# URL of the zip file (Source dados.gov.pt)
url = 'https://dados.gov.pt/s/resources/distritos-de-portugal/20181112-193106/distritos-shapefile.zip'

# Path for the sample_data folder
sample_data_folder = 'sample_data'
os.makedirs(sample_data_folder, exist_ok=True)  # create directory if it doesn't exist

# Fetch the zip file
response = requests.get(url, stream=True)

# Check if the request was successful
if response.status_code == 200:
    # Full path for the zip file
    zip_file_path = os.path.join(sample_data_folder, 'file.zip')

    # Save the zip file to the specified path
    with open(zip_file_path, 'wb') as zip_file:
        shutil.copyfileobj(response.raw, zip_file)

    # Extract the zip file
    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(sample_data_folder)

    # You can now work with the files in sample_data_folder
    print(f'The extracted files are located in: {sample_data_folder}')
else:
    print('Failed to download file, status code:', response.status_code)

# Please upload the font you wish to use to sample_data

# Path to your custom font
font_path = '/content/sample_data/ADLaMDisplay-Regular.ttf'

# Create a FontProperties object and set the font properties
font_properties = FontProperties(fname=font_path, size=16)

# Debug import
from google.colab import files

# Load and inspect the district shapefile
districts_gdf = gpd.read_file('/content/sample_data/distritos.shp')
# Exclude rows where 'TYPE_1' is 'Regi√µes aut√¥nomas'
districts_gdf = districts_gdf[districts_gdf['TYPE_1'] != 'Regi√µes aut√¥nomas']
# define the size of the hexagons
resolution = 5
# if it's not set or incorrect, set to the correct CRS (assuming EPSG:4326 here)
districts_gdf = districts_gdf.set_crs("EPSG:4326", allow_override=True)
# Create the Hexagons
hexagons = districts_gdf.h3.polyfill_resample(resolution)

# Create dataframe that counts the numnber of occurrences per district
total_incidents_by_district = data.groupby('district').size().reset_index(name='total_incident_count')

# Create uniformity between District Names
hexagons['district'] = hexagons['NAME_1'].str.upper().apply(unidecode.unidecode)
total_incidents_by_district['district'] = total_incidents_by_district['district'].str.upper().apply(unidecode.unidecode)

# Now, you should be able to merge and plot as previously described
merged_gdf = hexagons.merge(total_incidents_by_district, on='district', how='left')

# Replace NaNs with 0s (assuming that NaN means no incidents)
merged_gdf['total_incident_count'] = merged_gdf['total_incident_count'].fillna(0)


# Create the plot with a large figure size
fig, ax = plt.subplots(1, 1, figsize=(20, 20))  # You can adjust the size as needed

# Set a dark grey background color
fig.patch.set_facecolor('#2c2c2c')
ax.set_facecolor('#2c2c2c')

# Plot the hexagons, colored by total_incident_count using a blue color scheme
merged_gdf.plot(column='total_incident_count', ax=ax, cmap='Blues', legend=False)

# Remove axes for a cleaner look
ax.set_axis_off()
# Set the title with white color and custom font
plt.title(f'Ocorr√™ncias por Distrito\nPer√≠odo Analisado\n{start_date_str} a {end_date_str}',
          loc='left',
          color='white',
          fontproperties=font_properties)
# Save the figure with high resolution

filename=f'pt_hexagonal_{end_date_str}.png'
plt.savefig(filename, dpi=300, bbox_inches='tight')
files.download(filename)

# Show the plot
plt.show()

"""## Time Analysis (An√°lise Temporal)

**This block generates a set of graphics focused on the dataset's time frame**

**Results may vary based on the time period in your dataset**



---

**Este bloco gera um conjunto de gr√°ficos focados no per√≠odo do conjunto de dados**

**Os resultados podem variar com base no per√≠odo temporal do teu conjunto de dados**

#### Daily Number of Occurences (N√∫mero de Ocorr√™ncias di√°rias)

This code analyzes occurrence data by date, aiming to understand the daily distribution and average trends of occurrences. It extracts the date from the datetime information and groups the data by this date, calculating the total number of occurrences for each day. The script then computes the average number of daily occurrences.

A time series plot is created to visualize the daily counts. The plot is styled with a dark grid, and the data is represented as a blue line chart. An average line is drawn on the plot in red dashed style, indicating the average daily occurrences over the analyzed period. The chart is enhanced with a title, axis labels, and a legend, and the x-axis tick labels are rotated for better readability. The layout is adjusted to fit all elements neatly, and the final plot is saved as a high-resolution image for sharing or further use.


---


Este c√≥digo analisa dados de ocorr√™ncias por data, com o objetivo de entender a distribui√ß√£o di√°ria e as tend√™ncias m√©dias de ocorr√™ncias. Extrai a data das informa√ß√µes de data e hora e agrupa os dados por esta data, calculando o n√∫mero total de ocorr√™ncias para cada dia. O script ent√£o calcula a m√©dia do n√∫mero de ocorr√™ncias di√°rias.

Um gr√°fico de s√©ries temporais √© criado para visualizar as contagens di√°rias. O gr√°fico √© estilizado com uma grade escura, e os dados s√£o representados como um gr√°fico de linha azul. Uma linha m√©dia √© desenhada no gr√°fico em estilo tracejado vermelho, indicando as ocorr√™ncias di√°rias m√©dias durante o per√≠odo analisado. O gr√°fico √© aprimorado com um t√≠tulo, r√≥tulos de eixo e uma legenda, e os r√≥tulos de marca√ß√£o do eixo x s√£o rotacionados para melhor legibilidade. O layout √© ajustado para acomodar todos os elementos de forma ordenada, e o gr√°fico final √© salvo como uma imagem de alta resolu√ß√£o para compartilhamento ou uso posterior.


---



**In the future this average will be generated based on a fixed sample of the last 5 years, per month**

**No futuro esta m√©dia ser√° gerada baseada numa amostra fixa dos √∫ltimos 5 anos, por m√™s**
"""

incident_data_full = data

# Extract date from datetime for daily analysis
incident_data_full['date'] = incident_data_full['date_time'].dt.date

# Group the data by date and count the number of incidents for each day
daily_counts = incident_data_full.groupby('date').size()

# Calculate the average number of incidents per day
average_daily_incidents = daily_counts.mean()

# Create a time series plot
plt.figure(figsize=(15, 6))
sns.set_style("darkgrid")
sns.lineplot(x=daily_counts.index, y=daily_counts, color="blue")
plt.axhline(y=average_daily_incidents, color='red', linestyle='--', label=f'M√©dia Di√°ria do Per√≠odo Analisado:({average_daily_incidents:.0f})')
plt.title("N√∫mero de Ocorr√™ncias di√°rias", fontsize=16)
plt.xlabel("Data", fontsize=14)
plt.ylabel("N√∫mero de Ocorr√™ncias", fontsize=14)
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()

# Save the figure
filename=f'incidents_over_time_with_daily_average_{end_date_str}.png'
plt.savefig(filename, dpi=300,bbox_inches='tight')
files.download(filename)
plt.show()

"""#### Table of Occurences by weekday and hour ( Tabela de Ocorr√™ncias por dia da semana e hora)

**This code processes timestamp data, extracting the hour and the day of the week from a 'date_time' column in a DataFrame. It then creates a cross-tabulation (crosstab) between these extracted values, resulting in a tabular representation of incident counts organized by hour and day of the week. The code also includes mapping of day names to Portuguese for readability and orders the days correctly. The primary output is a heatmap visualization generated using Seaborn, showcasing the distribution of incidents across days of the week and hours of the day. Labels, titles, and annotations are added for context, and the resulting heatmap is saved as a high-resolution image, ready for sharing or further analysis, with the filename reflecting the end date of the analyzed period.**



---

**Este c√≥digo processa dados de via data/hora, extraindo a hora e o dia da semana de uma coluna 'date_time' em um DataFrame. Em seguida, cria uma tabula√ß√£o cruzada (crosstab) entre esses valores extra√≠dos, resultando em uma representa√ß√£o tabular das contagens de ocorr√™ncias organizadas por hora e dia da semana. O c√≥digo tamb√©m inclui mapeamento de nomes de dias para portugu√™s para facilitar a leitura e ordenar os dias corretamente. O resultado principal √© uma visualiza√ß√£o de mapa de calor gerada usando Seaborn, mostrando a distribui√ß√£o de incidentes entre os dias da semana e horas do dia. R√≥tulos, t√≠tulos e anota√ß√µes s√£o adicionados para contextualizar, e o mapa de calor resultante √© salvo como uma imagem de alta resolu√ß√£o, pronta para partilha ou an√°lise posterior, com o nome do arquivo refletindo a data de t√©rmino do per√≠odo analisado.**
"""

# Extract the hour and the day of the week
data['hour'] = data['date_time'].dt.hour
data['day_of_week'] = data['date_time'].dt.day_name()

# Create a crosstab of hour and day of the week
heatmap_data = pd.crosstab(data['hour'], data['day_of_week'])

# Portuguese days mapping
days_portuguese = {
    "Monday": "Segunda-feira",
    "Tuesday": "Ter√ßa-feira",
    "Wednesday": "Quarta-feira",
    "Thursday": "Quinta-feira",
    "Friday": "Sexta-feira",
    "Saturday": "S√°bado",
    "Sunday": "Domingo"
}
data['day_of_week_pt'] = data['day_of_week'].map(days_portuguese)

# Create a pivot table for the heatmap data
heatmap_data = data.pivot_table(index='hour', columns='day_of_week_pt', values='id', aggfunc='count', fill_value=0)

# Sort the days of the week in Portuguese
ordered_days = ["Segunda-feira", "Ter√ßa-feira", "Quarta-feira", "Quinta-feira", "Sexta-feira", "S√°bado", "Domingo"]


# Ensure all days are present in the heatmap, even if there's no data for them
for day in ordered_days:
    if day not in heatmap_data.columns:
        heatmap_data[day] = 0
heatmap_data = heatmap_data[ordered_days]  # ensure columns are ordered correctly

# Create the heatmap
plt.figure(figsize=(12, 8))
heatmap = sns.heatmap(heatmap_data, cmap='Blues', annot=True, fmt="g", linewidths=.5,cbar=False)
heatmap.set_title(f'Ocorr√™ncias por dia da semana e hora do dia\nPer√≠odo Analisado: {start_date_str} a {end_date_str}', fontdict={'fontsize': 18}, pad=12)
heatmap.set_xlabel('Dia da Semana', fontsize=13)
heatmap.set_ylabel('Hora do Dia', fontsize=13)
filename=f'incidents_by_day_week_{end_date_str}.png'
plt.savefig(filename, dpi=300,bbox_inches='tight')
files.download(filename)
plt.show()

"""#### Number of Occurences by Type (N√∫mero de Ocorr√™ncias por Tipo) - Top 20

**This code segment calculates and visualizes the counts of each incident type within a dataset. It generates a bar chart to represent the top 20 incident types based on their frequency, with the option to adjust the number of types shown. The chart is styled with a white background and a blue color palette for the bars. Labels, titles, and axes are included for clarity, enhancing interpretability. The layout is fine-tuned, and unnecessary spines are removed. Finally, the resulting bar chart is saved as a high-resolution image, named 'bar_chart_incidents_{end_date_str}.png,' indicating the end date of the analysis period, facilitating sharing or further analysis of incident type distribution during the specified timeframe.**



---
**Este segmento de c√≥digo calcula e visualiza as contagens de cada tipo de incidente no conjunto de dados. Gera um gr√°fico de barras para representar os 20 principais tipos de incidentes com base na sua frequ√™ncia, com a op√ß√£o de ajustar o n√∫mero de tipos mostrados. O gr√°fico tem um fundo branco e uma paleta de cores azul para as barras. R√≥tulos, t√≠tulos e eixos s√£o inclu√≠dos para maior clareza, melhorando a interpretabilidade. O layout √© ajustado e lombadas desnecess√°rias s√£o removidas. Por fim, o gr√°fico de barras resultante √© salvo como uma imagem de alta resolu√ß√£o, denominada 'bar_chart_incidents_{end_date_str}.png,' indicando a data final do per√≠odo de an√°lise, facilitando a partilha, arquivo, ou an√°lise adicional da distribui√ß√£o do tipo de incidente durante o per√≠odo especificado.**

"""

# Count the number of each type of incident. The number in head can be modified to show more, or less, types of occurrence
incident_counts = incident_data_full['natureza'].value_counts().head(20)
# Set the background style
sns.set(style="white")
# Create a bar chart
plt.figure(figsize=(12, 8))
sns.barplot(x=incident_counts.values, y=incident_counts.index, palette="Blues_d")
plt.title(f'N√∫mero de Ocorr√™ncias por Tipo\nPer√≠odo Analisado: {start_date_str} a {end_date_str}')
plt.xlabel('N√∫mero de Ocorr√™ncias')
plt.ylabel('Tipo de Ocorr√™ncia')
# Adjust the layout
plt.tight_layout()
# Remove the spines
sns.despine(left=True, bottom=True)
# Save and show the graph
filename=f'bar_chart_incidents_{end_date_str}.png'
plt.savefig(filename, dpi=300,bbox_inches='tight')
files.download(filename)
plt.show()

"""#### Number of Occurrences by District and Type of Occurrence (N√∫mero de Ocorr√™ncias por Distrito e por Tipo de Ocorr√™ncia) - Top 10


This code segment identifies the top 10 most common incident types within the dataset by counting their occurrences and subsequently filters the data to include only these top types. It then generates a stacked bar chart displaying the distribution of these top 10 incident types across different districts. The chart employs a 'viridis' colormap, clearly illustrating the variations in incident types within districts. Appropriately titled and labeled, the chart also includes a legend for incident type differentiation. To facilitate sharing and further analysis, the resulting stacked bar chart is saved as a high-resolution image with a filename denoting the end date of the analysis period. This image offers valuable insights into the prevalence of the top incident types across districts during the specified timeframe.


---

**Este segmento de c√≥digo identifica os 10 tipos de incidentes mais comuns no conjunto de dados atrav√©s da contagem das suas ocorr√™ncias e, subsequentemente, filtra os dados para incluir apenas estes tipos principais. Em seguida, gera um gr√°fico de barras empilhadas que apresenta a distribui√ß√£o destes 10 tipos de incidentes mais comuns em diferentes distritos. O gr√°fico utiliza um mapa de cores "viridis", ilustrando claramente as varia√ß√µes dos tipos de incidentes nos distritos. Com t√≠tulos e etiquetas apropriados, o gr√°fico tamb√©m inclui uma legenda para diferencia√ß√£o dos tipos de incidentes. Para facilitar a partilha e a an√°lise posterior, o gr√°fico de barras empilhadas resultante √© guardado como uma imagem de alta resolu√ß√£o com um nome de ficheiro que indica a data final do per√≠odo de an√°lise. Esta imagem oferece informa√ß√µes valiosas sobre a preval√™ncia dos principais tipos de incidentes nos distritos durante o per√≠odo de tempo especificado.**
"""

# Copy data dataframe for integrity purposes
incident_data_full = data
# Select the top 10 most common incident types
top_10_incidents = incident_data_full['natureza'].value_counts().nlargest(10)

# Filter the data to include only the top 10 incident types
top_10_incident_types = incident_data_full[incident_data_full['natureza'].isin(top_10_incidents.index)]

# Create a crosstab of district and top 10 incident types
district_type_ct = pd.crosstab(top_10_incident_types['district'], top_10_incident_types['natureza'])

# Create a stacked bar chart for the top 10 incidents
district_type_ct.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='viridis')
plt.title('N√∫mero de Ocorr√™ncias por Distrito e Top 10 Tipos')
plt.xlabel('Distrito')
plt.ylabel('N√∫mero de Ocorr√™ncias')
plt.legend(title='Tipo de Ocorr√™ncia', bbox_to_anchor=(1.05, 1), loc='upper left')
filename=f'stacked_bar_district_and_type_{end_date_str}.png'
plt.savefig(filename, dpi=300,bbox_inches='tight')
files.download(filename)
plt.show()

"""### Response Times (Tempos de Resposta)

**In this code snippet, Unix timestamps in the 'created.sec' and 'updated.sec' columns of the occurrence dataset are converted into standard datetime format, yielding 'created_datetime' and 'updated_datetime' columns. Subsequently, it calculates response times in minutes for each occurrence by computing the time elapsed between 'updated_datetime' and 'created_datetime.' Additionally, the code filters rows in the dataset based on the 'status' column, retaining those with 'Conclus√£o' (completed occurrences) and 'Chegada ao TO' (indicating arrival at the occurrence location). These filtered subsets, 'closed_incidents' and 'response_incidents,' will be used in the next code blocks**



---

**Neste trecho de c√≥digo, os carimbos de data/hora Unix nas colunas 'created.sec' e 'updated.sec' do conjunto de dados de ocorr√™ncia s√£o convertidos no formato datetime padr√£o, produzindo as colunas 'created_datetime' e 'updated_datetime'. Em seguida, calcula os tempos de resposta em minutos para cada ocorr√™ncia, calculando o tempo decorrido entre 'updated_datetime' e 'created_datetime'. Adicionalmente, o c√≥digo filtra as linhas do conjunto de dados com base na coluna 'status', retendo aquelas com 'Conclus√£o' (ocorr√™ncias conclu√≠das) e 'Chegada ao TO' (indicando a chegada ao local da ocorr√™ncia). Estes subconjuntos filtrados, 'incidentes_encerrados' e 'incidentes_resposta', ser√£o utilizados nos pr√≥ximos blocos de c√≥digo**

"""

# Convert 'created.sec' and 'updated.sec' from Unix time to regular datetime
incident_data_full['created_datetime'] = pd.to_datetime(incident_data_full['created.sec'], unit='s')
incident_data_full['updated_datetime'] = pd.to_datetime(incident_data_full['updated.sec'], unit='s')

# Calculate the response time in minutes
incident_data_full['response_time'] = (incident_data_full['updated_datetime'] - incident_data_full['created_datetime']).dt.total_seconds() / 60.0  # convert to minutes

# Filter rows where 'status' is 'Conclus√£o'
closed_incidents = incident_data_full.loc[incident_data_full['status'] == 'Conclus√£o']
# Filter rows where 'status' is 'Chegada ao TO'
response_incidents = incident_data_full.loc[incident_data_full['status'] == 'Chegada ao TO']

"""#### Box Plots (Diagrama de Caixa)


**This code segment generates two box plots to provide insights into occurrence data. The first box plot represents the distribution of Occurrence Duration, calculated as the difference between 'created.sec' and 'updated.sec' for occurrences marked as 'Completion.'**

**The second box plot visualizes Response Time, computed as the difference between 'created.sec' and 'updated.sec' for occurrences labeled 'Arrival at TO.'**

**The code sets the style and color palette, configures plot size, and defines boxplot attributes. Titles and labels are added for clarity, gridlines assist in interpretation, and the box around the plot is removed for simplicity. Both box plots are saved as images, facilitating further analysis and sharing of insights.**

#### Definitions

**Occurrence Duration**: difference between `created.sec` and `updated.sec` for all occurrences with status = `Conclus√£o`

Response Time: difference between created.sec and updated.sec for all events with status = `Chegada ao TO`


---
**Este segmento de c√≥digo gera dois diagaramas de caixa para fornecer informa√ß√µes sobre os dados de ocorr√™ncia. O primeiro diagrama de caixa representa a distribui√ß√£o da Dura√ß√£o da ocorr√™ncia, calculada como a diferen√ßa entre `created.sec` e 'updated.sec' para ocorr√™ncias marcadas como `Conclus√£o`.**

**O segundo diagrama de caixa visualiza o Tempo de resposta, calculado como a diferen√ßa entre `created.sec` e `updated.sec` para ocorr√™ncias marcadas como `Chegada ao TO`.**

**O c√≥digo define o estilo e a paleta de cores, configura o tamanho do gr√°fico e define os atributos do boxplot.Os t√≠tulos e as etiquetas s√£o adicionados para maior clareza, as linhas de grelha ajudam na interpreta√ß√£o e a caixa √† volta do gr√°fico √© removida para simplificar. Ambos os gr√°ficos de caixa s√£o guardados como imagens facilitando a an√°lise posterior e a partilha.**

#### Defini√ß√µes

**Dura√ß√£o da Ocorr√™ncia**: diferen√ßa entre `created.sec` e `updated.sec` para todas as ocorr√™ncias com `status` = `Conclus√£o`

**Tempo de Reposta**: diferen√ßa entre `created.sec` e `updated.sec` para todas as ocorr√™ncias com `status` = `Chegada ao TO`

##### Occurrence Duration (Dura√ß√£o das Ocorr√™ncias)
"""

# Box plot for response times
# Set style and color scheme
sns.set_style("whitegrid")
sns.set_palette("pastel")

# Create a larger plot
plt.figure(figsize=(14, 9))

# Create the boxplot with enhanced aesthetics
sns.boxplot(x=closed_incidents['response_time'], width=0.5, color="skyblue")

# Add a title and labels with larger fonts for clarity
plt.title('Distribui√ß√£o da Dura√ß√£o da Ocorr√™ncia', fontsize=20)
plt.xlabel('Dura√ß√£o da Ocorr√™ncia (minutos)', fontsize=16)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)

# Show gridlines for easier interpretation
plt.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.5)

# Remove the box around the plot to simplify the visuals (optional)
sns.despine()
#Save the plot
filename=f'box_response_time_{end_date_str}.png'
plt.savefig(filename, dpi=300)
files.download(filename)
# Show the plot
plt.show()

"""##### Response Time (Tempo de Resposta)"""

# Box plot for response times
# Set style and color scheme
sns.set_style("whitegrid")
sns.set_palette("pastel")

# Create a larger plot
plt.figure(figsize=(14, 9))

# Create the boxplot with enhanced aesthetics
sns.boxplot(x=response_incidents['response_time'], width=0.5, color="skyblue")

# Add a title and labels with larger fonts for clarity
plt.title('Distribui√ß√£o do Tempo de Resposta', fontsize=20)
plt.xlabel('Tempo de Resposta (minutos)', fontsize=16)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)

# Show gridlines for easier interpretation
plt.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.5)

# Remove the box around the plot to simplify the visuals (optional)
sns.despine()
#Save the plot
plt.savefig('box_response_time.png', dpi=300)
files.download('box_response_time.png')
# Show the plot
plt.show()

"""#### Histogram (Histograma)

**This code segment generates two histograms to provide insights into occurrence data. The first histogram represents the distribution of Occurrence Duration, calculated as the difference between `created.sec` and `updated.sec` for occurrences marked as `Conclus√£o`**

The second histogram visualizes Response Time, computed as the difference between `created.sec` and `updated.sec` for occurrences labeled `Chegada ao TO`.

**The code sets the style and color palette, configures plot size, and defines the histogram attributes. Titles and labels are added for clarity, gridlines assist in interpretation, and the box around the plot is removed for simplicity. Both histograms are saved as images, facilitating further analysis and sharing of insights.**

#### Definitions

**Occurrence Duration**: difference between `created.sec` and `updated.sec` for all occurrences with status = `Conclus√£o`

Response Time: difference between created.sec and updated.sec for all events with status = `Chegada ao TO`


---
**Este segmento de c√≥digo gera dois histogramas para fornecer informa√ß√µes sobre os dados de ocorr√™ncia. O primeiro histograma representa a distribui√ß√£o da Dura√ß√£o da ocorr√™ncia, calculada como a diferen√ßa entre `created.sec` e 'updated.sec' para ocorr√™ncias marcadas como `Conclus√£o`.**

**O segundo histograma visualiza o Tempo de resposta, calculado como a diferen√ßa entre `created.sec` e `updated.sec` para ocorr√™ncias marcadas como `Chegada ao TO`.**

**O c√≥digo define o estilo e a paleta de cores, configura o tamanho do gr√°fico e define os atributos do histograma. Os t√≠tulos e as etiquetas s√£o adicionados para maior clareza, as linhas de grelha ajudam na interpreta√ß√£o e a caixa √† volta do gr√°fico √© removida para simplificar. Ambos os hisogramas s√£o guardados como imagens facilitando a an√°lise posterior e a partilha.**

#### Defini√ß√µes

**Dura√ß√£o da Ocorr√™ncia**: diferen√ßa entre `created.sec` e `updated.sec` para todas as ocorr√™ncias com `status` = `Conclus√£o`

**Tempo de Reposta**: diferen√ßa entre `created.sec` e `updated.sec` para todas as ocorr√™ncias com `status` = `Chegada ao TO`

#####  Histogram for Occurence Duration (Histograma para Dura√ß√£o das Ocorr√™ncias)
"""

# Histogram for Occurence Duration
plt.figure(figsize=(12, 8))
sns.histplot(closed_incidents['response_time'], bins=30, kde=True)
plt.title('Histograma da Dura√ß√£o da Ocorr√™ncia')
plt.xlabel('Dura√ß√£o da Ocorr√™ncia (minutos)')
plt.ylabel('Frequ√™ncia')
#Save and show the histogram
filename=f'histogram_response_time_{end_date_str}.png'
plt.savefig(filename, dpi=300)
files.download(filename)
plt.show()

"""##### Histogram for Response Times (Histograma para tempos de Resposta)"""

# Histogram for response times
plt.figure(figsize=(12, 8))
sns.histplot(response_incidents['response_time'], bins=30, kde=True)
plt.title('Histograma do Tempo de Resposta')
plt.xlabel('Tempo de Resposta (minutos)')
plt.ylabel('Frequ√™ncia')
plt.savefig('histogram_response_time.png', dpi=300)
files.download('histogram_response_time.png')
plt.show()

"""## Scatter Plots (Gr√°ficos de Dispers√£o)

** In this block scatter plots are created to show the temporal distribution of events based per district and occurence type**


---
** Neste bloco s√£o criados gr√°ficos de dispers√£o para mostrar a distribui√ß√£o temporal dos eventos com base por distrito e tipo de ocorr√™ncia**

### Temporal Scatter Plot for every District (Gr√°fico de Dispers√£o Temporal para cada Distrito)

**This code segment aggregates occurrence data by `distrito` (district), `date_time` and `natureza`(occurence type) counting the number of occurrences. Each district is assigned a unique color for plotting, and a scatter plot is generated to visualize the data. Annotations are included optionally. The plot showcases occurrences by district over time, with the x-axis displaying date and time labels and the y-axis representing districts. Gridlines and borders are customized for clarity. The resulting scatter plot is saved as for further analysis and sharing within the notebook.**


---

**Este segmento de c√≥digo agrega dados de ocorr√™ncias por distrito', 'data_hora' e 'natureza', contando o n√∫mero de ocorr√™ncias. Cada distrito recebe uma cor exclusiva para plotagem e um gr√°fico de dispers√£o √© gerado para visualizar os dados. As anota√ß√µes s√£o inclu√≠das opcionalmente. O gr√°fico mostra as ocorr√™ncias por distrito ao longo do tempo, com o eixo x exibindo r√≥tulos de data e hora e o eixo y representando os distritos. As linhas de grade e as margens s√£o personalizadas para maior clareza. O gr√°fico de dispers√£o resultante √© gravado para an√°lise posterior e compartilhamento no notebook**
"""

# Group the data by 'district', 'date_time' and 'natureza' and count the number of occurrences
occurrences = incident_data_full.groupby(['district', 'date_time', 'natureza']).size().reset_index(name='count')

# Assign a unique color to each district
unique_districts = occurrences['district'].unique()


# Assign a blue colormap to each district
colors = plt.cm.Blues(np.linspace(0.3, 1, len(unique_districts)))  # Start from 0.3 instead of 0 to avoid very light colors
district_color_map = dict(zip(unique_districts, colors))

# Update color values for the plot
color_values = occurrences['district'].map(lambda district: district_color_map[district])

# Update color values for the plot
color_values = occurrences['district'].map(lambda district: district_color_map[district])

# Prepare data for plotting
x = occurrences['date_time']
y = occurrences['district'].map(lambda district: unique_districts.tolist().index(district))  # Convert districts to numerical categories for plotting
sizes = occurrences['count'] * 200  # Multiply by a factor to make the size differences more visible
color_values = occurrences['district'].map(lambda district: district_color_map[district])

# Create the figure and axes objects
fig, ax = plt.subplots(figsize=(15, 10))

# Create the scatter plot on the axes object
scatter = ax.scatter(x, y, c=color_values, s=sizes, alpha=0.8, marker='o')  # 'o' specifies a circular marker

# Add annotations: this is optional and it can be changed

# Annotation 1

annotation_time = datetime(2023, 10, 17, 2, 30)  # replace with the specific date and time you want
y_coordinate = 9  # replace with the y-coordinate at which you want the annotation to appear
ax.annotate('FMA ALINE',
            xy=(annotation_time, y_coordinate),
            xytext=(-120,60),
            textcoords='offset points',
            arrowprops=dict(facecolor='blue', edgecolor='blue',arrowstyle='->'),
            fontsize=12,
            color='white',
            bbox=dict(boxstyle="round,pad=0.3", alpha=0.6, facecolor='blue'))  # semi-transparent box

ax.axvline(x=annotation_time, color='blue', linestyle='--', linewidth=2)

# Annotation 2
annotation_time_2 = datetime(2023, 10, 19, 7, 00)  # replace with the specific date and time you want
y_coordinate = 9  # replace with the y-coordinate at which you want the annotation to appear
ax.annotate('FMA BABET',
            xy=(annotation_time_2, y_coordinate),
            xytext=(-120,60),
            textcoords='offset points',
            arrowprops=dict(facecolor='blue', edgecolor='blue',arrowstyle='->'),
            fontsize=12,
            color='white',
            bbox=dict(boxstyle="round,pad=0.3", alpha=0.6, facecolor='blue'))  # semi-transparent box
ax.axvline(x=annotation_time_2, color='blue', linestyle='--', linewidth=2)

# Annotation 3
annotation_time_3 = datetime(2023, 10, 22, 10, 30)  # replace with the specific date and time you want
y_coordinate = 9  # replace with the y-coordinate at which you want the annotation to appear
ax.annotate('FMA BERNARD',
            xy=(annotation_time_3, y_coordinate),
            xytext=(-120,60),
            textcoords='offset points',
            arrowprops=dict(facecolor='blue', edgecolor='blue',arrowstyle='->'),
            fontsize=12,
            color='white',
            bbox=dict(boxstyle="round,pad=0.3", alpha=0.6, facecolor='blue'))  # semi-transparent box
ax.axvline(x=annotation_time_3, color='blue', linestyle='--', linewidth=2)

# Customize gridlines
ax.yaxis.grid(False)  # Remove horizontal lines
ax.xaxis.grid(color='red', linestyle='--', linewidth=0.5)  # Red, dashed vertical lines

# Remove borders
for spine in ax.spines.values():
    spine.set_visible(False)

ax.set_title(f'Ocorr√™ncias por Distrito\nEvolu√ß√£o Temporal\n entre {start_date_str} e {end_date_str} ')
ax.set_xlabel('Data e Hora')
ax.set_ylabel('Distritos')
ax.set_yticks(range(len(unique_districts)))  # Set y-ticks to district names
ax.set_yticklabels(unique_districts)
plt.xticks(rotation=45,fontsize=8)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))  # format x-axis labels as date

plt.tight_layout()
filename =f'scatter_occurrences_per_district_{end_date_str}.png'
plt.savefig(filename, dpi=300,bbox_inches='tight')
files.download(filename)
plt.show()

"""#### Temporal Scatter Plot for type of Occurence (Gr√°fico de dispers√£o temporal por tipo de ocorr√™ncia)

**This code segment groups occurrence data by `natureza`(occurence type) and `date_time` tallying the number of occurrences for each combination. Unique colors are assigned to each 'natureza' type for plotting, and a scatter plot is generated to visualize the data. Optional annotations are included in the plot. The x-axis displays date and time labels, while the y-axis represents 'natureza' types. Gridlines and borders are customized for clarity. The resulting scatter plot is saved for further analysis and sharing within the notebook.**



---
**Este segmento de c√≥digo agrupa dados de ocorr√™ncia por `natureza`(tipo de ocorr√™ncia) e `date_time` contabilizando o n√∫mero de ocorr√™ncias para cada combina√ß√£o. Cores exclusivas s√£o atribu√≠das a cada tipo de 'natureza' para plotagem, e um gr√°fico de dispers√£o √© gerado para visualizar os dados. Anota√ß√µes opcionais est√£o inclu√≠das no gr√°fico. O eixo x exibe r√≥tulos de data e hora, enquanto o eixo y representa os tipos 'natureza'. As linhas de grade e as bordas s√£o personalizadas para maior clareza. O gr√°fico de dispers√£o resultante √© gravado para an√°lise posterior.**

"""

# Group the data by 'natureza', 'date_time' and count the number of occurrences
occurrences = data.groupby(['natureza', 'date_time']).size().reset_index(name='count')

# Assign a unique color to each 'natureza' type
unique_naturezas = occurrences['natureza'].unique()

# Assign a blue colormap to each 'natureza' type
colors = plt.cm.Blues(np.linspace(0.3, 1, len(unique_naturezas)))  # Start from 0.3 instead of 0 to avoid very light colors
natureza_color_map = dict(zip(unique_naturezas, colors))

# Update color values for the plot
color_values = occurrences['natureza'].map(lambda natureza: natureza_color_map[natureza])

# Prepare data for plotting
x = occurrences['date_time']
y = occurrences['natureza'].map(lambda natureza: unique_naturezas.tolist().index(natureza))  # Convert naturezas to numerical categories for plotting
sizes = occurrences['count'] * 200  # Multiply by a factor to make the size differences more visible

# Create the figure and axes objects
fig, ax = plt.subplots(figsize=(15, 10))

# Create the scatter plot on the axes object
scatter = ax.scatter(x, y, c=color_values, s=sizes, alpha=0.8, marker='o')  # 'o' specifies a circular marker

# Add annotations: this is optional

# Annotation 1
annotation_time = datetime(2023, 10, 17, 2, 30)  # replace with the specific date and time you want
y_coordinate = 9  # replace with the y-coordinate at which you want the annotation to appear
ax.annotate('FMA BABET',
            xy=(annotation_time, y_coordinate),
            xytext=(-120,60),
            textcoords='offset points',
            arrowprops=dict(facecolor='blue', edgecolor='blue',arrowstyle='->'),
            fontsize=12,
            color='white',
            bbox=dict(boxstyle="round,pad=0.3", alpha=0.6, facecolor='blue'))  # semi-transparent box
ax.axvline(x=annotation_time, color='blue', linestyle='--', linewidth=2)

# Annotation 2
annotation_time_2 = datetime(2023, 10, 19, 7, 00)  # replace with the specific date and time you want
y_coordinate = 9 # replace with the y-coordinate at which you want the annotation to appear
ax.annotate('FMA ALINE',
            xy=(annotation_time_2, y_coordinate),
            xytext=(-120,60),
            textcoords='offset points',
            arrowprops=dict(facecolor='blue', edgecolor='blue',arrowstyle='->'),
            fontsize=12,
            color='white',
            bbox=dict(boxstyle="round,pad=0.3", alpha=0.6, facecolor='blue'))  # semi-transparent box
ax.axvline(x=annotation_time_2, color='blue', linestyle='--', linewidth=2)

# Annotation 3
annotation_time_3 = datetime(2023, 10, 22, 10, 30)  # replace with the specific date and time you want
y_coordinate = 9  # replace with the y-coordinate at which you want the annotation to appear
ax.annotate('FMA BERNARD',
            xy=(annotation_time_3, y_coordinate),
            xytext=(-120,60),
            textcoords='offset points',
            arrowprops=dict(facecolor='blue', edgecolor='blue',arrowstyle='->'),
            fontsize=12,
            color='white',
            bbox=dict(boxstyle="round,pad=0.3", alpha=0.6, facecolor='blue'))  # semi-transparent box
ax.axvline(x=annotation_time_3, color='blue', linestyle='--', linewidth=2)

# Customize gridlines
ax.yaxis.grid(False)  # Remove horizontal lines
ax.xaxis.grid(color='red', linestyle='--', linewidth=0.5)  # Red, dashed vertical lines

# Remove borders
for spine in ax.spines.values():
    spine.set_visible(False)

# Title and labels
ax.set_title(f'Ocorr√™ncias por Natureza\nEvolu√ß√£o Temporal\n entre {start_date_str} e {end_date_str} ')
ax.set_xlabel('Data e Hora')
ax.set_ylabel('Natureza')
ax.set_yticks(range(len(unique_naturezas)))  # Set y-ticks to natureza names
ax.set_yticklabels(unique_naturezas)
plt.xticks(rotation=0, fontsize=6)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))  # format x-axis labels as date

plt.tight_layout()
filename=f'scatter_occurrences_over_time_{end_date_str}.png'
plt.savefig(filename, dpi=300,bbox_inches='tight')
files.download(filename)
plt.show()
